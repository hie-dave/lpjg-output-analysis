#'
#' Produce a standard set of plots for the tellaus report from the given
#' benchmark.
#'
#' @param benchmark A list with the following elements:
#' - maps: Temporally-aggregated dataset (one value per grid cell)
#' - trends: Temporal trends (one value per grid cell)
#' - seasonals: Seasonally-aggregated values (one value per month per gridcell)
#' - comparisons: Output of [DGVMTools::fullSpatialComparison]
#' - tables: List with two named data frames: "totals" and "metrics"
#' - benchmark: A [DGVMBenchmarks::DaveBenchmark] instance
#' @param settings Benchmarking settings as specified by the user
#' @param params Benchmarking parameters as specified by the user
#' @param overall_tables List of all tables
#' @param title Title for the plots
#'
#' @return Returns a list of HTML tags for rendering, or NULL if DGVMBenchmarks is not available
#' @import DGVMTools
#' @import ggplot2
#' @export
#'
do_tellaus_plots <- function(benchmark, settings, params, overall_tables, title) {
    if (!requireNamespace("DGVMBenchmarks", quietly = TRUE)) {
        warning("DGVMBenchmarks package is required for TellAus plot generation")
        return(NULL)
    }

    tags <- list()

    write_title <- function(title, level) {
        fname <- paste0("h", level)
        tag <- do.call(fname, list(title))
        tags[[length(tags) + 1L]] <<- tag
    }

    write_plot <- function(plt) {
        plt <- fix_xaxis_label_overlap(plt)
        tags[[length(tags) + 1L]] <<- plt
    }

    # Write top-level heading tag.
    write_title(title, 1)

    return(tags)
}

get_first_year <- function(comparison) {
    s1 <- comparison@sta.info1
    s2 <- comparison@sta.info2
    return(min(s1@first.year, s2@first.year))
}

get_last_year <- function(comparison) {
    s1 <- comparison@sta.info1
    s2 <- comparison@sta.info2
    return(max(s1@last.year, s2@last.year))
}

validate_comparison <- function(comparison) {
    if (comparison@quant1@units != comparison@quant2@units) {
        stop("Inconsistent units: "
                , comparison@quant1@units, " and "
                , comparison@quant2@units)
    }

    if (comparison@quant1@name != comparison@quant2@name) {
        stop("Inconsistent quantity names: "
             , comparison@quant1@name, " (", comparison@source1@name, ") and "
             , comparison@quant2@name, " (", comparison@source2@name, ")")
    }
}

validate_maps <- function(maps) {
    names <- unique(sapply(maps, function(x) x@quant@name))
    units <- unique(sapply(maps, function(x) x@quant@name))
    if (length(names) > 1) {
        stop("Inconsistent quantity names: ", names)
    }
    if (length(units) > 1) {
        stop("Inconsistent quantity units: ", units)
    }
}

#'
#' Fix overlapping longitude values on the x-axis of a spatial plot.
#'
#' @param plt A plot
#'
#' @keywords internal
#' @return [ggplot] A plot with fixed x-axis labels.
#'
fix_xaxis_label_overlap <- function(plt) {
    xlim <- ggplot2::layer_scales(plt)$x$get_limits()
    guide <- ggplot2::guide_axis(check.overlap = TRUE)
    return(plt + ggplot2::scale_x_continuous(guide = guide, limits = xlim))
}

#'
#' Add metric labels (e.g. r2, rmse, etc.) to a plot.
#'
#' @param benchmark A Benchmark object.
#' @param comparison Output of DGVMBenchmarks::fullSpatialComparison()
#' @param settings Benchmark settings, as defined in tellaus.rmd.
#' @param plt A ggplot object generated by [DGVMTools::plotSpatialComparison()]
#'
#' @keywords internal
#' @return [ggplot] A plot with fixed x-axis labels.
#'
add_metrics <- function(benchmark, comparisons, settings, plt) {
    lat_offset <- 0
    cnames <- names(comparisons) # Dave - BoM, Trunk - Bom, Dave - Trunk
    metrics <- benchmark@metrics
    # Only room for two metrics on the Australian plots.
    if (length(metrics) > 2) {
        metrics <- metrics[1:2]
    }
    for (metric in metrics) { # r2, RMSE, NMSE, r2_eff
        metric_label_df <- data.frame()
        for (comparison_name in cnames) {
            value <- round(comparisons[[comparison_name]]@stats[[metric]], 2)
            mname <- ifelse(metric == "r2_eff", "NSE", metric)
            metric_label_df <- rbind(metric_label_df
                                     , list(label = paste(mname, "=", value)
                                     , Facet = comparison_name
                                     , x = settings$stats_lon
                                     , y = settings$stats_lat - lat_offset)
                                     , stringsAsFactors = FALSE)
        }
        metric_label_df$Facet <- factor(metric_label_df$Facet, cnames)
        plt <- plt + geom_text(data = metric_label_df
                               , mapping = aes(x = x, y = y, label = label)
                               , size = settings$annotation_text_size)
        lat_offset <- lat_offset + 4
    }
    return(plt)
}

#'
#' Create an absolute values differenes plot panel for use in the tellaus
#' benchmarks.
#'
#' @param benchmark Output of one of the benchmark_* functions.
#' @param settings Benchmark settings as defined in tellaus.rmd.
#'
#' @export
#' @import DGVMTools
#' @import ggplot2
#' @return [ggplot] A list of tags
#'
plot_absolute_deltas <- function(benchmark, settings) {
    comparisons <- benchmark$comparisons[["Values"]]

    # Basic sensibility checks.
    if (length(comparisons) < 1) {
        stop("No comparisons to plot")
    }

    lapply(comparisons, validate_comparison)

    first_year <- min(sapply(comparisons, get_first_year))
    last_year <- max(sapply(comparisons, get_last_year))

    units <- comparisons[[1]]@quant1@units
    # units_per_month <- bquote(.(units) ~ month^-1)
    var <- comparisons[[1]]@quant1@name
    subtitle <- paste(first_year, last_year, sep = "-")
    plt <- plotSpatialComparison(
        comparisons,
        ncol = settings$num_cols,
        legend.title = bquote(.(units)),
        text.multiplier = settings$text_multiplier,
        map.overlay = settings$map_overlay,
        title = paste(var, "Biases"),
        subtitle = subtitle,
        panel.bg.col = "white"
    )

    plt <- add_metrics(benchmark$benchmark, comparisons, settings, plt)
    plt <- fix_xaxis_label_overlap(plt)
    return(plt)
}

#'
#' Create a spatial plot of the absolute values of the given dataset.
#'
#' @param benchmark The benchmark, the output of one of the benchmark_*
#' functions included in this package. Should be a list.
#' @param settings A list of benchmarking settings as in tellaus.rmd.
#'
#' @keywords internal
#' @return [ggplot] A ggplot object.
#'
plot_absolute_values <- function(benchmark, settings, limits = NULL) {
    # Basic sensibility checks.
    if (!("maps" %in% names(benchmark))) {
        stop("Benchmark does not contain a 'map' element")
    }

    maps <- benchmark$maps
    if (length(maps) < 1) {
        stop("No data to plot")
    }

    validate_maps(maps)

    first_year <- min(sapply(maps, get_first_year))
    last_year <- max(sapply(maps, get_last_year))
    subtitle <- paste(first_year, last_year, sep = "-")

    units <- maps[[1]]@quant@units
    var <- maps[[1]]@quant@name

    plt <- plotSpatial(benchmark$maps
                       , ncol = settings$num_cols
                       , legend.title = bquote(.(units))
                       , map.overlay = settings$map_overlay
                       , text.multiplier = settings$text_multiplier
                       , title = paste("Absolute", var, "values")
                       , limits = limits
                       , subtitle = subtitle)

    plt <- fix_xaxis_label_overlap(plt)
    return(plt)
}

#'
#' Create a table of metrics.
#'
#' The table will have the following columns:
#' - Dataset
#' - Quantity
#' - Simulation
#'
#' The table will have one column per metric and one row per simulation.
#'
#' @param benchmark A [DGVMTools::Benchmark] object containing metadata.
#' @param comparison A list of [DGVMTools::Comparison] objects, typically the
#' output of fullSpatialComparison()[["Values"]], or the output of sequential
#' calls to CompareLayers(), concatenated into a single list.
#' @param simulations A list of [DGVMTools::Source] objects.
#' @param ndigit The number of decimal digits in the output table.
#'
#' @keywords internal
#' @return [data.frame] A data table.
make_metric_table <- function(benchmark, comparisons, simulations, ndigit = 3) {

    # Prepare the (empty) table of benchmarking metrics.
    col_names <- c("Dataset", "Quantity", "Simulation", benchmark@metrics)

    # Create one empty line.
    empty_line <- as.list(rep("-", length(col_names)))
    names(empty_line) <- col_names

    # Create the output table.
    metric_table <- data.frame(check.names = FALSE, stringsAsFactors = FALSE)

    for (dataset in benchmark@datasets) {
        for (sim in simulations) {
            # Get comparison name.
            # FIXME: fragile
            name <- paste(sim@name, "-", dataset@source@name)
            if (!(name %in% names(comparisons))) {
                warning("Comparison not found: ", name)
                next()
            }

            line <- copy(empty_line)
            # dataset is a Field object.
            line$Dataset <- dataset@source@name

            # benchmark is a Benchmark object.
            line$Quantity <- benchmark@id

            # sim is a Source object
            line$Simulation <- sim@name

            for (metric in benchmark@metrics) {
                value <- comparisons[[name]]@stats[[metric]]
                line[[metric]] <- signif(value, ndigit)
            }

            # Append row to table.
            metric_table <- rbind(metric_table, data.frame(line))
        }
    }

    names(metric_table) <- col_names
    return(metric_table)
}

#'
#' Get a colour representing the goodness of a metric value.
#'
#' @param metric Metric name (e.g. NSE, RMSE, etc).
#' @param value Metric value.
#'
#' @return [character] A colour representing the goodness of a particular value.
#'
#' @keywords internal
#'
get_colour <- function(metric, value) {
    colour_good <- "green"
    colour_avg <- "orange"
    colour_bad <- "red"
    if (is.na(value)) {
        return("black")
    }
    if (metric == "NSE") {
        if (value > 0) {
            return(colour_good)
        }
        return(colour_bad)
    }
    if (metric == "R^2^") {
        if (value > 0.66) {
            return(colour_good)
        } else if (value > 0.33) {
            return(colour_avg)
        } else {
            return(colour_bad)
        }
    }
    if (metric == "RMSE") {
        return("")
    }
    if (metric == "NMSE") {
        if (value < 0.5) {
            return(colour_good)
        } else if (value < 1) {
            return(colour_avg)
        } else {
            return(colour_bad)
        }
    }
    stop("Unknown metric: ", metric)
}

#'
#' Format a metric table.
#'
#' Colour code the metric values according to their goodess, add links to plots,
#' etc.
#'
#' @param metrics Names of enabled metrics.
#' @param metric_table The metric table.
#'
#' @return [kable] A kable table.
#'
#' @export
#' @import knitr
#' @import kableExtra
#'
format_metric_table <- function(metrics, metric_table) {
    # TODO: refactor out the metrics argument. This could be determined by
    # setdiff() with names(metric_table).
    tbl <- kable(metric_table) %>% kable_styling(full_width = TRUE)
    if (nrow(metric_table) > 0) {
        names(metric_table) <- gsub("r2_eff", "NSE", names(metric_table))
        names(metric_table) <- gsub("r2", "R^2^", names(metric_table))

        # TODO: make use of these columns?
        to_remove <- c("Data bootstrap", "Data mean", "Dataset ref.")
        metric_table <- metric_table[, setdiff(names(metric_table), to_remove)]

        for (metric in c(metrics, "NSE", "R^2^")) {
            if (!metric %in% names(metric_table)) {
                next()
            }
            i <- which(names(metric_table) == metric)
            cols <- sapply(metric_table[[metric]], \(x) get_colour(metric, x))
            tbl <- tbl %>% column_spec(i, color = cols)
        }
    }
    return(tbl)
}
